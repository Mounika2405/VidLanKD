{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mounika.k/VidLanKD/S3D_HowTo100M'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../S3D_HowTo100M/')\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from s3dg import S3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "net = S3D('s3d_dict.npy', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model weights\n",
    "net.load_state_dict(th.load('s3d_howto100m.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video input should be of size Batch x 3 x T x H x W and normalized to [0, 1] \n",
    "video = th.rand(2, 3, 32, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation mode\n",
    "net = net.eval()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video inference\n",
    "video_output = net(video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_embedding': tensor([[ 0.0026,  0.0196,  0.0014,  ..., -0.0070,  0.0169, -0.0165],\n",
       "         [ 0.0032,  0.0204,  0.0032,  ..., -0.0052,  0.0156, -0.0184]],\n",
       "        grad_fn=<AddmmBackward>),\n",
       " 'mixed_5c': tensor([[5.5793e-03, 4.9334e-05, 2.5326e-03,  ..., 1.5103e-04, 2.0989e-03,\n",
       "          1.5248e-03],\n",
       "         [6.8382e-03, 0.0000e+00, 2.2347e-03,  ..., 1.2149e-04, 1.9135e-03,\n",
       "          1.6861e-03]], grad_fn=<MeanBackward2>)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text inference\n",
    "text_output = net.text_module(['open door', 'cut tomato'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_embedding': tensor([[-4.9127,  2.3569, -7.3506,  ..., -4.4715, -1.4505,  1.0537],\n",
       "         [-7.9459, -6.9406, -1.3840,  ...,  5.7514,  2.2345,  4.8926]],\n",
       "        grad_fn=<AddmmBackward>)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_embedding = video_output['video_embedding']\n",
    "text_embedding = text_output['text_embedding']\n",
    "# We compute all the pairwise similarity scores between video and text.\n",
    "similarity_matrix = th.matmul(text_embedding, video_embedding.t())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1573,  0.9702],\n",
       "        [-5.5916, -5.8234]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: opencv-python in /home/mounika.k/.local/lib/python3.7/site-packages (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/mounika.k/.local/lib/python3.7/site-packages (from opencv-python) (1.21.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/dataset/packages/python/3.7/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --user opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"/ssd_scratch/users/mounika.k/HowTo100M/3JOfQAwkRjE.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'cv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-392c69a89fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_CAP_PROP_FPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'cv'"
     ]
    }
   ],
   "source": [
    "cap.set(c, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width 455.0\n",
      "height 256.0\n",
      "fps 29.97002997002997\n",
      "frame count 5835.0\n"
     ]
    }
   ],
   "source": [
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH )\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT )\n",
    "fps =  cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "print('width', width)\n",
    "print('height', height)\n",
    "print('fps', fps)\n",
    "print('frame count', frame_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: The video network is fully convolutional (with global average pooling in time and space at the end). However, we recommend using T=32 frames (same as during training), T=16 frames also works ok. For H and W we have been using values from 200 to 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# vidcap = cv2.VideoCapture(\"/path/to/video\")\n",
    "success, image = cap.read()\n",
    "count = 0\n",
    "\n",
    "while success:\n",
    "    cv2.imshow('frame', image)\n",
    "#     height, width, layers = image.shape\n",
    "# #     new_h = height / 2\n",
    "# #     new_w = width / 2\n",
    "#     resize = cv2.resize(image, (256, 200))\n",
    "#     cv2.imwrite(\"%03d.jpg\" % count, resize)\n",
    "#     success, image = cap.read()\n",
    "#     count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5d18f67e2576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#check if the video capture is open\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error Opening Video Stream Or File\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#check if the video capture is open\n",
    "if(cap.isOpened() == False):\n",
    "    print(\"Error Opening Video Stream Or File\")\n",
    "\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame =cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        if cv2.waitKey(25)  == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rescale_frame(frame, percent=75):\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "\n",
    "while True:\n",
    "    rect, frame = cap.read()\n",
    "    frame75 = rescale_frame(frame, percent=75)\n",
    "    cv2.imshow('frame75', frame75)\n",
    "    frame150 = rescale_frame(frame, percent=150)\n",
    "    cv2.imshow('frame150', frame150)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.VideoCapture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('frame', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "clip = mp.VideoFileClip(\"/ssd_scratch/users/mounika.k/HowTo100M/3JOfQAwkRjE.mp4\")\n",
    "clip_resized = clip.resize(height=200, width=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 455, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.empty([256, 455, 3])\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plugin': 'ffmpeg', 'nframes': inf, 'ffmpeg_version': '4.2.2-static https://johnvansickle.com/ffmpeg/ built with gcc 8 (Debian 8.3.0-6)', 'codec': 'mpeg4', 'pix_fmt': 'yuv420p', 'fps': 29.97, 'source_size': (455, 256), 'size': (455, 256), 'rotate': 0, 'duration': 194.7}\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "filename = '/ssd_scratch/users/mounika.k/HowTo100M/3JOfQAwkRjE.mp4'\n",
    "vid = imageio.get_reader(filename,  'ffmpeg')\n",
    "\n",
    "# for image in vid.iter_data():\n",
    "#     print(image.shape)\n",
    "    \n",
    "metadata = vid.get_meta_data()\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5835.159"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "194.7 * 29.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5835"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.count_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 455, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 455, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFMPEG_BIN = \"ffmpeg\" # on Linux ans Mac OS\n",
    "# FFMPEG_BIN = \"ffmpeg.exe\" # on Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "command = [ FFMPEG_BIN,\n",
    "            '-r', '32',\n",
    "            '-i', '/ssd_scratch/users/mounika.k/HowTo100M/3JOfQAwkRjE.mp4',\n",
    "            '-f', 'image2pipe',\n",
    "            '-pix_fmt', 'rgb24',\n",
    "            '-vcodec', 'rawvideo', '-']\n",
    "pipe = sp.Popen(command, stdout = sp.PIPE, bufsize=10**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mounika.k/.local/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 11182080 into shape (3,32,200,456)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3c96636c8b30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# transform the byte read into a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m456\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# throw away the data in the pipe's buffer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 11182080 into shape (3,32,200,456)"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "# read 420*360*3 bytes (= 1 frame)\n",
    "raw_image = pipe.stdout.read(32*256*455*3)\n",
    "# transform the byte read into a numpy array\n",
    "image =  numpy.fromstring(raw_image, dtype='uint8')\n",
    "image = image.reshape((3, 32, 200, 456))\n",
    "# throw away the data in the pipe's buffer.\n",
    "pipe.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106,  90,  84, ..., 173, 174, 179], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imshow('image', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor\n",
    " \n",
    "'''\n",
    "Grabbing The video's from storage\n",
    "syntax:\n",
    "variable_holding_video_name= moviepy.editor.VideoFileCLip(\"{{Filename}}.{{extension}}\")\n",
    "   \n",
    "'''\n",
    "clip_1= moviepy.editor.VideoFileClip(\"Video_1.mp4\")\n",
    "clip_2= moviepy.editor.VideoFileClip(\"Video_2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "\u001b[K     |████████████████████████████████| 388 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /home/mounika.k/.local/lib/python3.7/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /home/mounika.k/.local/lib/python3.7/site-packages (from moviepy) (4.61.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /home/mounika.k/.local/lib/python3.7/site-packages (from moviepy) (2.25.1)\n",
      "Collecting proglog<=1.0.0\n",
      "  Downloading proglog-0.1.9.tar.gz (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/mounika.k/.local/lib/python3.7/site-packages (from moviepy) (1.21.2)\n",
      "Collecting imageio<3.0,>=2.5\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 42.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio_ffmpeg>=0.2.0\n",
      "  Downloading imageio_ffmpeg-0.4.5-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.9 MB 270 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pillow in /home/dataset/packages/pytorch/1.1.0/lib/python3.7/site-packages (from imageio<3.0,>=2.5->moviepy) (6.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mounika.k/.local/lib/python3.7/site-packages (from requests<3.0,>=2.8.1->moviepy) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mounika.k/.local/lib/python3.7/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/mounika.k/.local/lib/python3.7/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/mounika.k/.local/lib/python3.7/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.0.4)\n",
      "Building wheels for collected packages: moviepy, proglog\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110743 sha256=b53d333ed64c02879b8898bfc19cd2847517d23cb7c6e246f150c18097cfde69\n",
      "  Stored in directory: /home/mounika.k/.cache/pip/wheels/56/dc/2b/9cd600d483c04af3353d66623056fc03faed76b7518faae4df\n",
      "  Building wheel for proglog (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for proglog: filename=proglog-0.1.9-py3-none-any.whl size=6156 sha256=4c8e5230468488f188cac75ce2595a7c3c34ab9752851447491cbdabd6c88628\n",
      "  Stored in directory: /home/mounika.k/.cache/pip/wheels/12/36/1f/dc61e6ac10781d63cf6fa045eb09fa613a667384e12cb6e6e0\n",
      "Successfully built moviepy proglog\n",
      "Installing collected packages: proglog, imageio-ffmpeg, imageio, moviepy\n",
      "Successfully installed imageio-2.9.0 imageio-ffmpeg-0.4.5 moviepy-1.0.3 proglog-0.1.9\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/dataset/packages/python/3.7/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --user moviepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !pip3 install --user moviepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> References </b>\n",
    " - https://github.com/antoine77340/S3D_HowTo100M\n",
    " - https://scikit-image.org/docs/dev/user_guide/video.html\n",
    " - https://arxiv.org/pdf/1912.06430.pdf\n",
    " - http://zulko.github.io/blog/2013/09/27/read-and-write-video-frames-in-python-using-ffmpeg/\n",
    " - https://gist.github.com/keithweaver/70df4922fec74ea87405b83840b45d57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
